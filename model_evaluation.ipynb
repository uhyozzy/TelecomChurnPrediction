{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**변수와 모델명을 바꾸어 사용하세요 !**"
      ],
      "metadata": {
        "id": "8b0B66bF3Nc0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "분류 평가지표 만드는 함수"
      ],
      "metadata": {
        "id": "KUFIH0wB3YRc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gV6iELoJ3Hww"
      },
      "outputs": [],
      "source": [
        "# report for model evaluation\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, classification_report, precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "\n",
        "def model_report(model):\n",
        "    y_pred = model.predict(x_test)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    # AUC - ROC curve\n",
        "    y_score = model.predict_proba(x_test)[:,1]\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
        "    model_roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    model_f1_score_macro = precision_recall_fscore_support(y_test, y_pred, average=\"macro\")[2]\n",
        "    model_f1_score_weighted = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")[2]\n",
        "    model_sensitivity = precision_recall_fscore_support(y_test, y_pred, average=\"binary\", pos_label=1)[0]\n",
        "    model_specificity = precision_recall_fscore_support(y_test, y_pred, average=\"binary\", pos_label=0)[0]\n",
        "    model_precision = precision_recall_fscore_support(y_test, y_pred, average=\"binary\", pos_label=1)[1]\n",
        "    model_recall = precision_recall_fscore_support(y_test, y_pred, average=\"binary\", pos_label=1)[2]\n",
        "\n",
        "    # Calculating f2 score\n",
        "    beta = 2\n",
        "    model_f2_score = (1 + beta**2) * (model_precision * model_recall) / ((beta**2 * model_precision) + model_recall)\n",
        "\n",
        "    print(\"Confusion Matrix\\n\", cm, \"\\n\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['No Churn', 'Churn']))\n",
        "    print(\"Accuracy Score      : \", accuracy_score(y_test, y_pred).round(4))\n",
        "    print(\"Area Under Curve    : \", model_roc_auc.round(4))\n",
        "    print(\"F1 Score (macro)    : \", model_f1_score_macro.round(4))\n",
        "    print(\"F1 Score (weighted) : \", model_f1_score_weighted.round(4))\n",
        "    print(\"F2 Score            : \", model_f2_score.round(4))\n",
        "    print(\"Sensitivity         : \", model_sensitivity.round(4))\n",
        "    print(\"Specificity         : \", model_specificity.round(4))\n",
        "    print(\"Precision           : \", model_precision.round(4))\n",
        "    print(\"Recall              : \", model_recall.round(4), \"\\n\")\n",
        "\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.plot([0, 1], ls=\"--\")\n",
        "    plt.plot([0, 0], [1, 0], c=\".7\"), plt.plot([1, 1], c=\".7\")\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "출력값"
      ],
      "metadata": {
        "id": "Uks4PlfX3aSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_report(svm)"
      ],
      "metadata": {
        "id": "a0sU-WlX3Mox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "교차검증 정확도평균 / 테스트데이터 정확도 평균"
      ],
      "metadata": {
        "id": "LLvqnD7d7S1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# 모델 생성\n",
        "model = svm\n",
        "\n",
        "# 교차 검증을 통해 모델의 일반화 성능을 평가합니다.\n",
        "cv_scores = cross_val_score(model, x_train_over, y_train_over, cv=5)  # 5-폴드 교차 검증\n",
        "print(\"교차 검증 정확도 평균:\", np.mean(cv_scores))\n",
        "\n",
        "# 모델을 학습 데이터로 학습시킵니다.\n",
        "model.fit(x_train_over, y_train_over)\n",
        "\n",
        "# 테스트 데이터로 모델을 평가합니다.\n",
        "y_pred = model.predict(x_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"테스트 데이터 정확도:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "5m3TOGVJ7TBo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}